# ğŸ“– åŸºäº Qwen2.5-7B çš„æŒ‡ä»¤å¾®è°ƒå®ä½“è¯†åˆ«ï¼ˆNERï¼‰
## ğŸš€ ä¸€ã€é¡¹ç›®ç®€ä»‹
æœ¬é¡¹ç›®æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨LoRA/QLoRA æŠ€æœ¯å¯¹Qwen2.5-7B-Instructæ¨¡å‹è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Tuningï¼‰ï¼Œä»¥å®Œæˆç”Ÿç‰©åŒ»å­¦å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ä»»åŠ¡ã€‚é¡¹ç›®å®ç°äº†ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹è¯„ä¼°çš„å®Œæ•´æµç¨‹ï¼Œå¹¶é›†æˆ **SwanLab** è¿›è¡Œè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ã€‚

## ğŸ“Š äºŒã€æ•°æ®é›†æ¥æºï¼š
bc2gmå‘½åå®ä½“è¯†åˆ«æ•°æ®é›†ã€‚

ä¸‹è½½åœ°å€ï¼šhttps://github.com/spyysalo/bc2gm-corpus?utm_source=chatgpt.com
## ğŸš€ ä¸‰ã€ç¯å¢ƒä¸æ–‡ä»¶ç»“æ„
### é¡¹ç›®ç»“æ„
```
qwen_ner
â”œâ”€â”€ README.md
â”œâ”€â”€ config_loader.py
â”œâ”€â”€ data
â”‚   â””â”€â”€ bc2gm1
â”œâ”€â”€ data_process.py
â”œâ”€â”€ download_model.py
â”œâ”€â”€ model.py
â”œâ”€â”€ output
â”‚   â””â”€â”€ bc2gm1
â”‚       â”œâ”€â”€ qwen_ner_LoRA
â”‚       â””â”€â”€ qwen_ner_QLoRA
â”œâ”€â”€ pre_models
â”‚   â””â”€â”€ Qwen2.5-7B-Instruct
â”œâ”€â”€ predict.py
â”œâ”€â”€ qwen_ner_config
â”‚   â”œâ”€â”€ lora_config.json
â”‚   â””â”€â”€ qlora_config.json
â”œâ”€â”€ swanlog
â”œâ”€â”€ trainer.py
â””â”€â”€ utils.py
```
###  ä¾èµ–å®‰è£…

```
pip install transformers peft  bitsandbytes torch 
pip install swanlab tqdm numpy
```
## ğŸš€å››ã€å¿«é€Ÿå¼€å§‹
### è®­ç»ƒç»ƒ/è¯„ä¼°
ç›´æ¥è¿è¡Œtrainer.pyå³å¯ã€‚
```
python main.py
```
### æµ‹è¯•

ç›´æ¥è¿è¡Œpredict.pyå³å¯ã€‚
```
python predict.py
```
## äº”ã€å®éªŒç»“æœ
### ğŸ“Š å¾®è°ƒæ–¹æ³•æ€§èƒ½å¯¹æ¯”

| å¾®è°ƒæ–¹æ³• | Batch Size | æ˜¾å­˜å ç”¨ (è¿‘ä¼¼) | F1 Score (å‚è€ƒ) |
| :---: | :---: | :---: | :---: |
| **LoRA (BF16)** | 4 | ~25GB | 82.7% |
| **QLoRA (4-bit)** | 4 | ~13 GB | 82.1% |